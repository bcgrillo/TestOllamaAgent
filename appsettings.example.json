{
  "ClientConfiguration": {
    "Ollama": {
      "Endpoint": "http://localhost:11434"
    },
    "AzureAI": {
      "BaseUrl": "https://models.github.ai/inference",
      "ApiKey": "YOUR_GITHUB_PAT_HERE",
      "AvailableModels": [ "mistral-small-2503" ]
    }
  }
}